# üß† Atelier 2 ‚Äì Apprentissage Supervis√© avec Python

Projet r√©alis√© dans le cadre de la 5e ann√©e du d√©partement MAM √† Polytech Lyon dans le cours de *Machine Learning* encadr√© par **Haytham Elghazel**.

---

## üéØ Objectif du projet

Mettre en ≈ìuvre un **pipeline complet de classification supervis√©e** appliqu√© √† des donn√©es de scoring de cr√©dit, en explorant :

- Le pr√©traitement des donn√©es (donn√©es manquantes, variables h√©t√©rog√®nes, etc.)
- Le feature engineering et la s√©lection de variables
- L‚Äô√©valuation comparative de plusieurs algorithmes
- L‚Äôoptimisation et l‚Äôautomatisation via des pipelines

---

## üìÅ Contenu du TP

### I. Classification supervis√©e sur `credit_scoring.csv`

#### üîß √âtapes :
1. **Chargement et pr√©paration des donn√©es**
   - S√©paration en variables explicatives et cible (`status`)
   - S√©paration apprentissage/test √† 50%

2. **Classification avec 3 mod√®les :**
   - Arbre de d√©cision CART
   - k-plus-proches-voisins (k=5)
   - Perceptron multi-couche [40, 20]

3. **Normalisation des donn√©es continues** (`StandardScaler` ou `MinMaxScaler`)

4. **R√©duction de dimension** via ACP (PCA ‚Äì 3 composantes)

5. **S√©lection de variables pertinentes** via `RandomForestClassifier`

6. **Tuning des hyperparam√®tres** avec `GridSearchCV`

7. **Cr√©ation d‚Äôun pipeline Scikit-learn** :
   - Normalisation ‚Üí PCA (optionnelle) ‚Üí Meilleur classifieur
   - Sauvegarde du mod√®le avec `pickle`

---

### II. √âtude de donn√©es h√©t√©rog√®nes sur `credit.data`

#### ‚öôÔ∏è √âtapes :
1. **Nettoyage des donn√©es num√©riques**
   - Suppression des `?`
   - Binarisation de la cible

2. **Imputation des valeurs manquantes**
   - Moyenne pour les num√©riques
   - Valeur la plus fr√©quente pour les cat√©gorielles

3. **Encodage des variables cat√©gorielles** (`OneHotEncoder`)

4. **Normalisation + fusion finale des donn√©es**

5. **Ex√©cution de `run_classifiers` sur ces donn√©es**

---

## üî¨ Comparaison de mod√®les

Comparaison de plusieurs classifieurs avec `cross_val_score` et `KFold` :

- `KNN`, `CART`, `ID3`, `MLP`, `RandomForest`, `XGBoost`, `AdaBoost`, `Bagging`, etc.
- √âvaluations :
  - Accuracy, Rappel, Pr√©cision
  - AUC ROC
  - Temps d'ex√©cution

Une fonction `run_classifiers()` est fournie pour automatiser cette √©tape.

---

## üõ†Ô∏è Stack technique

| Outil / Librairie   | R√¥le |
|---------------------|------|
| `numpy`, `pandas`   | Manipulation des donn√©es |
| `matplotlib`        | Visualisation |
| `scikit-learn`      | Mod√©lisation, pipelines, pr√©traitement |
| `xgboost`           | Mod√®le performant de boosting |
| `pickle`            | Sauvegarde du pipeline |

---

## ‚ñ∂Ô∏è Ex√©cution

1. Cloner le d√©p√¥t :
```bash
git clone https://github.com/ton-user/atelier-apprentissage-supervise.git
